##의사결정 트리
	Decision Block(의사결정 블록, 사각형)
	Terminal Block(단말 블록, 타원형)
	Branch(가지)

#장점
	*적은 계산 비용
		-kNN은 많이 계산 비용
	*이해하기 쉬운 학습 결과
		-flowchart로 그려저서 이해하기 쉬움
	*누락된 값 있어도 처리 가능
		-kNN은 그 값을 채워주어야 함
	*분류와 무관한 특징도 처리 가능
		-대표적으로 회귀에 쓰일 수 있음
#단점
	*과적합(overfitting)되기 쉬움,너무 복잡한 의사결정 트리
		-학습데이터에 너무 맞아 떨어진 구조라 과적합이 되기 쉽다.

#학습(의사결정 트리에서): 결정 트리 학습법
	트리 형태로 데이터를 구축하는 것이 의사결정 트리에서의 학습이다.

#의사결정 트리에는 여러가지 방법이 있다. 우리는 그 중에서 ID3를 배운다.

#준비
	*명목형 값은 그냥 사용하면 되지만
	 연속형 값은 구간으로 분리하여 양자화 시켜야 한다.

#가장 적합한 분할 기준을 선택하는 방법
	*정보 이득
	*지니 불순도
	*분산 감소

#정보 이득(Information gain)
	*데이터를 분할하기 이전과 이후의 정보량(엔트로피) 변화
	*정보 이득이 가장 큰 특징에 대해 분할 수행
	*정보 이득으로 정보의 불확실성(엔트로피) 감소

#엔트로피는 정보에 대한 기대값이다.
	엔트로피가 높을수록 정보는 무질서 또는 불확실하다고 할 수 있다.
	확률에 정보량을 곱하는 것이 엔트로피이다.
	정보량이라는 것은 (나는 필요한 정보량이라고 생각) 

#정보 이득(다시)
	정보 이득은 부모 엔트로피에서 분류 후 자식 엔트로피의 값을 뺀 것이다.
	위에서 말했듯이 엔트로피가 낮을수록 정보량은 확실한 것이고 질서가 있는 것이다.
	따라서 자식 엔트로피의 값이 낮을수록 분류가 잘 된 것이므로
	부모 엔트로피-자식 엔트로피의 값이 높을수록 잘 분류된 것이라고 할 수 있다.

